{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')    ## I don't like pandas setting with copy warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FYI: GDD has no data for Somalia. I have included it in my list tho\n",
    "\n",
    "emro = ['AFG', 'ARE', 'BHR', 'DJI','EGY','IRN','IRQ','JOR',\n",
    "        'KWT', 'LBN', 'LBR', 'MAR', 'OMN', 'PAK','PSE' , 'QAT','SAU',\n",
    "        'SDN','SOM', 'SYR', 'YEM','TUN']\n",
    "drop_list = ['superregion2','age','urban','edu']\n",
    "\n",
    "def select(col, val,df):\n",
    "        df = df[df[col] == val]\n",
    "        return df\n",
    "\n",
    "def emro_select(df:pd.DataFrame):\n",
    "    d1 = select('age',999,df)\n",
    "    d2 = select('edu',999,d1)\n",
    "    d3 = select('urban',999,d2)\n",
    "    d3 = d3.drop(drop_list,axis=1)\n",
    "#     d4 = d3[d3['iso3'].isin(emro)]\n",
    "\n",
    "    all = select('female',999,d3)\n",
    "    males = select('female',0,d3)\n",
    "    females = select('female',1,d3)\n",
    "        \n",
    "    return all, males, females "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_quantile_scores(df, value_column, quantiles=[0.2, 0.4, 0.6, 0.8]):\n",
    "    # calculate the quantiles\n",
    "    quantile_values = df[value_column].quantile(quantiles)\n",
    "    \n",
    "    # Function to assign score based on quantile\n",
    "    def get_score(value):\n",
    "        if value <= quantile_values[quantiles[0]]:\n",
    "            return 1\n",
    "        elif value <= quantile_values[quantiles[1]]:\n",
    "            return 2\n",
    "        elif value <= quantile_values[quantiles[2]]:\n",
    "            return 3\n",
    "        elif value <= quantile_values[quantiles[3]]:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5  \n",
    "    # apply the function to assign scores\n",
    "    df['score'] = df[value_column].apply(get_score)\n",
    "    return df\n",
    "\n",
    "def neg_quantile_scores(df, value_column, quantiles=[0.2, 0.4, 0.6, 0.8]):\n",
    "    # calculate the quantiles\n",
    "    quantile_values = df[value_column].quantile(quantiles)\n",
    "    \n",
    "    # Function to assign score based on quantile\n",
    "    def get_score(value):\n",
    "        if value <= quantile_values[quantiles[0]]:\n",
    "            return 5\n",
    "        elif value <= quantile_values[quantiles[1]]:\n",
    "            return 4\n",
    "        elif value <= quantile_values[quantiles[2]]:\n",
    "            return 3\n",
    "        elif value <= quantile_values[quantiles[3]]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1  \n",
    "    # apply the function to assign scores\n",
    "    df['score'] = df[value_column].apply(get_score)\n",
    "    return df\n",
    "\n",
    "def alpha_score(data: pd.DataFrame, type: str) -> pd.DataFrame:\n",
    "    years = data['year'].unique()\n",
    "    scores = []\n",
    "\n",
    "    for i in years:\n",
    "        year_df = select('year', i, data)  \n",
    "        \n",
    "        # Process the DataFrame based on the `type`\n",
    "        if type == 'plant':\n",
    "            year_df = pos_quantile_scores(year_df,'median')  \n",
    "            scores.append(year_df)\n",
    "        elif type == 'animal':\n",
    "            year_df = neg_quantile_scores(year_df,'median')  \n",
    "            scores.append(year_df)\n",
    "        else:\n",
    "            print('Fix your type') \n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the type is invalid\n",
    "\n",
    "    # Concatenate all the DataFrames collected in the list\n",
    "    scores_df = pd.concat(scores, axis=0)\n",
    "    return scores_df\n",
    "\n",
    "def get_pivots(df):\n",
    "    cf = df.pivot_table(index='year', columns='iso3', values='score').transpose()\n",
    "    return cf \n",
    "\n",
    "def aio (path:str, type:str, pivot:bool=True):\n",
    "    full_data = pd.read_csv(path)\n",
    "    all, males, females = emro_select(full_data)\n",
    "\n",
    "    all = alpha_score(all,type)\n",
    "    males = alpha_score(males,type)\n",
    "    females = alpha_score(females,type)\n",
    "\n",
    "    if pivot == True:\n",
    "        all = get_pivots(all)\n",
    "        males = get_pivots(males)\n",
    "        females = get_pivots(females)\n",
    "    \n",
    "    return all, males, females\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the same function as before but doesn't read the files \n",
    "def aio_v2 (df:pd.DataFrame, type:str, pivot:bool=True):\n",
    "    all, males, females = emro_select(df)\n",
    "\n",
    "    all = alpha_score(all,type)\n",
    "    males = alpha_score(males,type)\n",
    "    females = alpha_score(females,type)\n",
    "\n",
    "    ###! next three lines are there to keep only the emro countries... this is for the global calculation that I will do next \n",
    "    ###? but these lines won't affect this emro region calculation; but I will comment them out anyway.\n",
    "    \n",
    "    all = all[all['iso3'].isin(emro)]\n",
    "    females = females[females['iso3'].isin(emro)]\n",
    "    males = males[males['iso3'].isin(emro)]\n",
    "    \n",
    "    if pivot == True:\n",
    "        all = get_pivots(all)\n",
    "        males = get_pivots(males)\n",
    "        females = get_pivots(females)\n",
    "    \n",
    "    return all, males, females\n",
    "\n",
    "def plant_based_score (name:str, save:bool, v0_codes:list, type:str):\n",
    "    def sum_csv_files(file_paths, sum_columns):\n",
    "        df_sum = None\n",
    "        non_sum_columns = None\n",
    "        \n",
    "        for file in file_paths:\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Separate the columns to sum and the other columns\n",
    "            df_sum_cols = df[sum_columns]\n",
    "            df_non_sum_cols = df.drop(columns=sum_columns)\n",
    "            \n",
    "            if df_sum is None:\n",
    "                df_sum = df_sum_cols\n",
    "                non_sum_columns = df_non_sum_cols  # Keep the non-summed columns from the first file\n",
    "            else:\n",
    "                # Sum the specified columns, aligned by index\n",
    "                df_sum = df_sum.add(df_sum_cols, fill_value=0)\n",
    "        \n",
    "        # Concatenate the non-summed columns back with the summed columns\n",
    "        final_df = pd.concat([non_sum_columns, df_sum], axis=1)\n",
    "        \n",
    "        return final_df\n",
    "\n",
    "    total = sum_csv_files(v0_codes,sum_columns=['median'])\n",
    "    all, males, females = aio_v2(total,type=type,pivot=True)\n",
    "    os.makedirs('scores\\plant_global',exist_ok=True)\n",
    "    if save:\n",
    "        all.to_csv(f'scores\\plant_global\\{name}_all.csv')\n",
    "        males.to_csv(f'scores\\plant_global\\{name}_males.csv')\n",
    "        females.to_csv(f'scores\\plant_global\\{name}_females.csv')\n",
    "    return all, males, females\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ichigo = [([r'..\\raw_data\\Country-level estimates\\v08_cnty.csv'],'whole_grain','plant'), \n",
    "           ([r'..\\raw_data\\Country-level estimates\\v01_cnty.csv'],'fruit','plant' ),\n",
    "           ([r'..\\raw_data\\Country-level estimates\\v02_cnty.csv',\n",
    "             r'..\\raw_data\\Country-level estimates\\v04_cnty.csv'],'veg','plant'),\n",
    "             ([r'..\\raw_data\\Country-level estimates\\v06_cnty.csv'],'nuts', 'plant'),\n",
    "             ([r'..\\raw_data\\Country-level estimates\\v05_cnty.csv'],'legumes','plant'),\n",
    "             ([r'..\\raw_data\\Country-level estimates\\v31_cnty.csv',\n",
    "               r'..\\raw_data\\Country-level estimates\\v29_cnty.csv'],'veg_oil','plant'),\n",
    "               ([r'..\\raw_data\\Country-level estimates\\v17_cnty.csv',\n",
    "                 r'..\\raw_data\\Country-level estimates\\v18_cnty.csv'],'tea_coffee','plant'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v07_cnty.csv'],'refined_grain','plant'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v03_cnty.csv'],'potatoes','plant'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v15_cnty.csv'],'SSB','plant'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v35_cnty.csv'],'sugar','plant'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v28_cnty.csv'],'SFA','animal'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v12_cnty.csv'],'eggs','animal'),\n",
    "                 ([r'..\\raw_data\\Country-level estimates\\v57_cnty.csv',\n",
    "                   r'..\\raw_data\\Country-level estimates\\v14_cnty.csv',\n",
    "                   r'..\\raw_data\\Country-level estimates\\v13_cnty.csv'],'dairy','animal'),\n",
    "                   ([r'..\\raw_data\\Country-level estimates\\v09_cnty.csv',\n",
    "                     r'..\\raw_data\\Country-level estimates\\v10_cnty.csv'],'meats','animal'),\n",
    "                     ([r'..\\raw_data\\Country-level estimates\\v11_cnty.csv'],'sea_food','animal')]\n",
    "\n",
    "for i, j, k in ichigo:\n",
    "    _,_,_ = plant_based_score(name=j,save=True,v0_codes=i,type=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a function to sum the scores for countries \n",
    "\n",
    "def calc_total(path: str, suff: str):\n",
    "    all_glob = glob.glob(f'{path}/*_{suff}.csv')\n",
    "    \n",
    "    cumulative_df = None\n",
    "\n",
    "    for i in all_glob:\n",
    "        temp = pd.read_csv(i)\n",
    "        \n",
    "        if cumulative_df is None:\n",
    "            cumulative_df = temp\n",
    "        else:\n",
    "            cumulative_df.iloc[:, 1:] += temp.iloc[:, 1:]\n",
    "    \n",
    "    return cumulative_df\n",
    "\n",
    "folder = 'scores/plant_global'  \n",
    "for i in ['all', 'males', 'females']:\n",
    "    temp_df = calc_total(folder, i)\n",
    "    temp_df.to_csv(f'{folder}/total_{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in **plant_emro** we have scores based on how countries scored in the EMRO region\n",
    "\n",
    "and in **plant_global** we have thier scores based on how they scored across the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
