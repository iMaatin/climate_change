{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4df92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55cdb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define EMRO countries and helper functions\n",
    "emro = ['AFG', 'ARE', 'BHR', 'DJI','EGY','IRN','IRQ','JOR',\n",
    "        'KWT', 'LBN', 'LBR', 'MAR', 'OMN', 'PAK','PSE' , 'QAT','SAU',\n",
    "        'SDN','SOM', 'SYR', 'YEM','TUN']\n",
    "drop_list = ['superregion2','age','urban','edu']\n",
    "\n",
    "def select(col, val, df):\n",
    "    df = df[df[col] == val]\n",
    "    return df\n",
    "\n",
    "def emro_select(df: pd.DataFrame):\n",
    "    d1 = select('age', 999, df)\n",
    "    d2 = select('edu', 999, d1)\n",
    "    d3 = select('urban', 999, d2)\n",
    "    d3 = d3.drop(drop_list, axis=1)\n",
    "    d4 = d3[d3['iso3'].isin(emro)]\n",
    "\n",
    "    all = select('female',999,d4)\n",
    "    males = select('female',0,d4)\n",
    "    females = select('female',1,d4)\n",
    "        \n",
    "    return all, males, females \n",
    "\n",
    "\n",
    "def get_pivots(df):\n",
    "    cf = df.pivot_table(index='year', columns='iso3', values='score').transpose()\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59272ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated dash_score function that uses the new gram-based cutoffs.\n",
    "def medit_score(df: pd.DataFrame, food_group: str, scoring_scheme: str) -> pd.DataFrame:\n",
    "\n",
    "    dash_cutoffs = {\n",
    "        'dairy': 400,         # Dairy. For pos: higher intake is better.\n",
    "        'fruit': 480,         # Fruits.\n",
    "        'veg': 480,           # Vegetables.\n",
    "        'fish':28.5,           # Fish.\n",
    "        'bread':180,\n",
    "        'legumes':28.5,\n",
    "        'nuts':168,\n",
    "        'eggs':31.4\n",
    "    }\n",
    "    \n",
    "    if food_group not in dash_cutoffs:\n",
    "        raise ValueError(f\"No DASH cutoff defined for food group '{food_group}'\")\n",
    "    \n",
    "    cutoff_val = dash_cutoffs[food_group]\n",
    "    \n",
    "    if scoring_scheme == 'hi':\n",
    "        # For positive scoring: score 1 if median >= cutoff.\n",
    "        df['score'] = df['median'].apply(lambda x: 1 if x >= cutoff_val else 0)\n",
    "    elif scoring_scheme == 'low':\n",
    "        # For negative scoring: score 1 if median <= cutoff.\n",
    "        df['score'] = df['median'].apply(lambda x: 1 if x <= cutoff_val else 0)\n",
    "    else:\n",
    "        raise ValueError(\"scoring_scheme must be 'pos' or 'neg'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def aio_medit(df: pd.DataFrame, food_group: str, scoring_scheme: str, pivot: bool=True):\n",
    "    all_df, males_df, females_df = emro_select(df)\n",
    "    \n",
    "    all_df = medit_score(all_df, food_group, scoring_scheme)\n",
    "    males_df = medit_score(males_df, food_group, scoring_scheme)\n",
    "    females_df = medit_score(females_df, food_group, scoring_scheme)\n",
    "    \n",
    "    all_df = all_df[all_df['iso3'].isin(emro)]\n",
    "    males_df = males_df[males_df['iso3'].isin(emro)]\n",
    "    females_df = females_df[females_df['iso3'].isin(emro)]\n",
    "    \n",
    "    if pivot:\n",
    "        all_df = get_pivots(all_df)\n",
    "        males_df = get_pivots(males_df)\n",
    "        females_df = get_pivots(females_df)\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "def get_medit_scores(name: str, save: bool, v0_codes: list, scoring_scheme: str):\n",
    "    \n",
    "    def sum_csv_files(file_paths, sum_columns):\n",
    "        df_sum = None\n",
    "        non_sum_columns = None\n",
    "        for file in file_paths:\n",
    "            df = pd.read_csv(file)\n",
    "            # Separate columns for summing versus metadata.\n",
    "            df_sum_cols = df[sum_columns]\n",
    "            df_non_sum_cols = df.drop(columns=sum_columns)\n",
    "            if df_sum is None:\n",
    "                df_sum = df_sum_cols\n",
    "                non_sum_columns = df_non_sum_cols  # Retain meta columns from the first file.\n",
    "            else:\n",
    "                df_sum = df_sum.add(df_sum_cols, fill_value=0)\n",
    "        final_df = pd.concat([non_sum_columns, df_sum], axis=1)\n",
    "        return final_df\n",
    "\n",
    "    total = sum_csv_files(v0_codes, sum_columns=['median'])\n",
    "    \n",
    "    all_df, males_df, females_df = aio_medit(total, food_group=name, scoring_scheme=scoring_scheme, pivot=True)\n",
    "    \n",
    "    os.makedirs('scores/medit_new/global', exist_ok=True)\n",
    "    if save:\n",
    "        all_df.to_csv(f'scores/medit_new/{name}_all.csv')\n",
    "        males_df.to_csv(f'scores/medit_new/{name}_males.csv')\n",
    "        females_df.to_csv(f'scores/medit_new/{name}_females.csv')\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "\n",
    "# List of tuples with (file paths, food group name, scoring scheme).\n",
    "ryuk = [\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v08_cnty.csv'], 'bread', 'hi'), \n",
    "    ([r'..\\raw_data\\Country-level estimates\\v01_cnty.csv'], 'fruit', 'hi'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v02_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v04_cnty.csv'], 'veg', 'hi'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v06_cnty.csv'], 'nuts', 'hi'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v05_cnty.csv'], 'legumes', 'hi'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v57_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v14_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v13_cnty.csv'], 'dairy', 'low'),\n",
    "    # ([r'..\\raw_data\\Country-level estimates\\v09_cnty.csv',\n",
    "    #   r'..\\raw_data\\Country-level estimates\\v10_cnty.csv'], 'meats', 'low'),  ###! I'll have to do this one seprately.\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v11_cnty.csv'], 'fish', 'hi'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v12_cnty.csv'], 'eggs', 'hi'),\n",
    "]\n",
    "\n",
    "# Loop through each configuration and generate (and optionally save) the scores.\n",
    "for file_list, food_group, scheme in ryuk:\n",
    "    get_medit_scores(name=food_group, save=True, v0_codes=file_list, scoring_scheme=scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de10087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medit_meats(processed: str, unprocessed: str, save: bool = True):\n",
    "    \"\"\"\n",
    "    Combines nut and legume consumption (normalized), scores them according to DASH criteria,\n",
    "    and saves the resulting DataFrames in the same format as other DASH scoring outputs.\n",
    "    \"\"\"\n",
    "    # Load the datasets\n",
    "    df_pro = pd.read_csv(processed)\n",
    "    df_unpro = pd.read_csv(unprocessed)\n",
    "\n",
    "    # Normalize intakes\n",
    "    df_pro['median'] = df_pro['median'] / 30        ### processed meat: 1 serving = 30g\n",
    "    df_unpro['median'] = df_unpro['median'] / 85     ### unprocessed meat: 1 serving = 85g\n",
    "\n",
    "    # Sum normalized values\n",
    "    df_combined = df_pro.copy()\n",
    "    df_combined['median'] = df_pro['median'] + df_unpro['median']\n",
    "\n",
    "    df_combined['score'] = df_combined['median'].apply(lambda x: 1 if x <= 2 else 0)\n",
    "\n",
    "    all_df, males_df, females_df = emro_select(df_combined)\n",
    "    all_df = all_df[all_df['iso3'].isin(emro)]\n",
    "    males_df = males_df[males_df['iso3'].isin(emro)]\n",
    "    females_df = females_df[females_df['iso3'].isin(emro)]\n",
    "\n",
    "    all_df = get_pivots(all_df)\n",
    "    males_df = get_pivots(males_df)\n",
    "    females_df = get_pivots(females_df)\n",
    "\n",
    "    if save:\n",
    "        os.makedirs('scores/medit_new/global', exist_ok=True)\n",
    "        all_df.to_csv('scores/medit_new/meats_all.csv')\n",
    "        males_df.to_csv('scores/medit_new/meats_males.csv')\n",
    "        females_df.to_csv('scores/medit_new/meats_females.csv')\n",
    "\n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "_,_,_ = get_medit_meats(\n",
    "    processed=r'..\\raw_data\\Country-level estimates\\v09_cnty.csv',\n",
    "    unprocessed=r'..\\raw_data\\Country-level estimates\\v10_cnty.csv',\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e86f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a function to sum the scores for countries \n",
    "def calc_total(path: str, suff: str):\n",
    "    all_glob = glob.glob(f'{path}/*_{suff}.csv')\n",
    "    cumulative_df = None\n",
    "    \n",
    "    for i in all_glob:\n",
    "        temp = pd.read_csv(i)\n",
    "        \n",
    "        if cumulative_df is None:\n",
    "            cumulative_df = temp\n",
    "        else:\n",
    "            cumulative_df.iloc[:, 1:] += temp.iloc[:, 1:]\n",
    "    \n",
    "    return cumulative_df\n",
    "\n",
    "folder = 'scores/medit_new'  \n",
    "for i in ['all', 'males', 'females']:\n",
    "    temp_df = calc_total(folder, i)\n",
    "    temp_df.to_csv(f'{folder}/total_{i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
