{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')    ## I don't like pandas setting with copy warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FYI: GDD has no data for Somalia. I have included it in my list tho\n",
    "\n",
    "emro = ['AFG', 'ARE', 'BHR', 'DJI','EGY','IRN','IRQ','JOR',\n",
    "        'KWT', 'LBN', 'LBR', 'MAR', 'OMN', 'PAK','PSE' , 'QAT','SAU',\n",
    "        'SDN','SOM', 'SYR', 'YEM','TUN']\n",
    "drop_list = ['superregion2','age','urban','edu']\n",
    "\n",
    "def select(col, val,df):\n",
    "        df = df[df[col] == val]\n",
    "        return df\n",
    "\n",
    "def emro_select(df:pd.DataFrame):\n",
    "    \n",
    "    d1 = select('age',999,df)\n",
    "    d2 = select('edu',999,d1)\n",
    "    d3 = select('urban',999,d2)\n",
    "    d3 = d3.drop(drop_list,axis=1)\n",
    "#     d4 = d3[d3['iso3'].isin(emro)]\n",
    "\n",
    "    all = select('female',999,d3)\n",
    "    males = select('female',0,d3)\n",
    "    females = select('female',1,d3)\n",
    "        \n",
    "    return all, males, females \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivots(df):\n",
    "    \"\"\"\n",
    "    Pivot the DataFrame so that scores are arranged with years as rows and ISO3 codes as columns.\n",
    "    \"\"\"\n",
    "    cf = df.pivot_table(index='year', columns='iso3', values='score').transpose()\n",
    "    return cf \n",
    "\n",
    "\n",
    "# Updated dash_score function that uses the new gram-based cutoffs.\n",
    "def dash_score(df: pd.DataFrame, food_group: str, scoring_scheme: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Score the DASH metric based on the new gram-based cutoffs.\n",
    "\n",
    "    For 'pos' scoring: assign a 1 if the median is greater than or equal to the cutoff.\n",
    "    For 'neg' scoring: assign a 1 if the median is less than the cutoff.\n",
    "    \"\"\"\n",
    "    dash_cutoffs = {\n",
    "        'meats': 510,         # Meats/Poultry/Fish. For neg: lower intake is better.\n",
    "        'dairy': 400,         # Dairy. For pos: higher intake is better.\n",
    "        'fruit': 320,         # Fruits.\n",
    "        'veg': 320,           # Vegetables.\n",
    "        'whole_grain': 180,   # Whole Grains.\n",
    "        'SSB': 178.6,         # Sugar-sweetened beverages.\n",
    "        'sugar': 178.6,       # Sugar (assumed same as SSB).\n",
    "        'sodium': 2300        # Sodium in mg/day.\n",
    "    }\n",
    "    \n",
    "    if food_group not in dash_cutoffs:\n",
    "        raise ValueError(f\"No DASH cutoff defined for food group '{food_group}'\")\n",
    "    \n",
    "    cutoff_val = dash_cutoffs[food_group]\n",
    "    \n",
    "    if scoring_scheme == 'pos':\n",
    "        # For positive scoring: score 1 if median >= cutoff.\n",
    "        df['score'] = df['median'].apply(lambda x: 1 if x >= cutoff_val else 0)\n",
    "    elif scoring_scheme == 'neg':\n",
    "        # For negative scoring: score 1 if median < cutoff.\n",
    "        df['score'] = df['median'].apply(lambda x: 1 if x < cutoff_val else 0)\n",
    "    else:\n",
    "        raise ValueError(\"scoring_scheme must be 'pos' or 'neg'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def aio_v3_dash(df: pd.DataFrame, food_group: str, scoring_scheme: str, pivot: bool=True):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame for DASH scoring:\n",
    "      1. Splits the data into subgroups (all, males, females) using emro_select.\n",
    "      2. Applies DASH scoring based on the new gram-based cutoffs.\n",
    "      3. Restricts the DataFrame to only EMRO countries.\n",
    "      4. Optionally pivots the data to have years as rows and iso3 codes as columns.\n",
    "    \"\"\"\n",
    "    # Split into groups.\n",
    "    all_df, males_df, females_df = emro_select(df)\n",
    "    \n",
    "    # Apply DASH scoring based on the food group and scoring scheme.\n",
    "    all_df = dash_score(all_df, food_group, scoring_scheme)\n",
    "    males_df = dash_score(males_df, food_group, scoring_scheme)\n",
    "    females_df = dash_score(females_df, food_group, scoring_scheme)\n",
    "    \n",
    "    # Filter only to the EMRO countries.\n",
    "    all_df = all_df[all_df['iso3'].isin(emro)]\n",
    "    males_df = males_df[males_df['iso3'].isin(emro)]\n",
    "    females_df = females_df[females_df['iso3'].isin(emro)]\n",
    "    \n",
    "    if pivot:\n",
    "        all_df = get_pivots(all_df)\n",
    "        males_df = get_pivots(males_df)\n",
    "        females_df = get_pivots(females_df)\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "def get_dash_scores(name: str, save: bool, v0_codes: list, scoring_scheme: str):\n",
    "    \"\"\"\n",
    "    Sums the CSV files for a given DASH food group (via provided file paths),\n",
    "    computes the DASH scores using the new cutoffs, and optionally saves the resulting DataFrames.\n",
    "    \"\"\"\n",
    "    def sum_csv_files(file_paths, sum_columns):\n",
    "        df_sum = None\n",
    "        non_sum_columns = None\n",
    "        for file in file_paths:\n",
    "            df = pd.read_csv(file)\n",
    "            # Separate columns for summing versus metadata.\n",
    "            df_sum_cols = df[sum_columns]\n",
    "            df_non_sum_cols = df.drop(columns=sum_columns)\n",
    "            if df_sum is None:\n",
    "                df_sum = df_sum_cols\n",
    "                non_sum_columns = df_non_sum_cols  # Retain meta columns from the first file.\n",
    "            else:\n",
    "                df_sum = df_sum.add(df_sum_cols, fill_value=0)\n",
    "        final_df = pd.concat([non_sum_columns, df_sum], axis=1)\n",
    "        return final_df\n",
    "\n",
    "    # Sum the CSV files (here summing the 'median' column).\n",
    "    total = sum_csv_files(v0_codes, sum_columns=['median'])\n",
    "    \n",
    "    # Process with DASH scoring; pivot the output.\n",
    "    all_df, males_df, females_df = aio_v3_dash(total, food_group=name, scoring_scheme=scoring_scheme, pivot=True)\n",
    "    \n",
    "    # Create directory for saving if needed.\n",
    "    os.makedirs('scores/dash_cutoff/global', exist_ok=True)\n",
    "    if save:\n",
    "        all_df.to_csv(f'scores/dash_cutoff/{name}_all.csv')\n",
    "        males_df.to_csv(f'scores/dash_cutoff/{name}_males.csv')\n",
    "        females_df.to_csv(f'scores/dash_cutoff/{name}_females.csv')\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Configuration for DASH scoring with new cutoff values and file addresses.\n",
    "luffy = [ \n",
    "    ([r'..\\raw_data\\Country-level estimates\\v08_cnty.csv'], 'whole_grain', 'pos'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v01_cnty.csv'], 'fruit', 'pos'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v02_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v04_cnty.csv'], 'veg', 'pos'),  # Note: Includes starchy veggies.\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v15_cnty.csv'], 'SSB', 'neg'),\n",
    "    # ([r'..\\raw_data\\Country-level estimates\\v35_cnty.csv'], 'sugar', 'neg'),  # Sugar may be handled separately.\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v57_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v14_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v13_cnty.csv'], 'dairy', 'pos'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v09_cnty.csv',\n",
    "      r'..\\raw_data\\Country-level estimates\\v11_cnty.csv',  # Total seafoods added.\n",
    "      r'..\\raw_data\\Country-level estimates\\v10_cnty.csv'], 'meats', 'neg'),\n",
    "    ([r'..\\raw_data\\Country-level estimates\\v37_cnty.csv'], 'sodium', 'neg')\n",
    "]\n",
    "\n",
    "# Loop through each configuration and generate (and optionally save) the DASH scores.\n",
    "for files, food_group, scheme in luffy:\n",
    "    get_dash_scores(name=food_group, save=True, v0_codes=files, scoring_scheme=scheme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dash_scores_nuts_legumes_combined(nuts_file: str, legumes_file: str, save: bool = True):\n",
    "    \"\"\"\n",
    "    Combines nut and legume consumption (normalized), scores them according to DASH criteria,\n",
    "    and saves the resulting DataFrames in the same format as other DASH scoring outputs.\n",
    "    \"\"\"\n",
    "    # Load the datasets\n",
    "    df_nuts = pd.read_csv(nuts_file)\n",
    "    df_legumes = pd.read_csv(legumes_file)\n",
    "\n",
    "    # Normalize intakes\n",
    "    df_nuts['median'] = df_nuts['median'] / 28\n",
    "    df_legumes['median'] = df_legumes['median'] / 100\n",
    "\n",
    "    # Sum normalized values\n",
    "    df_combined = df_nuts.copy()\n",
    "    df_combined['median'] = df_nuts['median'] + df_legumes['median']\n",
    "\n",
    "    # Apply DASH scoring: score = 1 if median >= 5/7, else 0\n",
    "    df_combined['score'] = df_combined['median'].apply(lambda x: 1 if x >= 5/7 else 0)\n",
    "\n",
    "    # Process the data (no need to re-score in aio_v3_dash, just use for EMRO filtering + split)\n",
    "    all_df, males_df, females_df = emro_select(df_combined)\n",
    "    all_df = all_df[all_df['iso3'].isin(emro)]\n",
    "    males_df = males_df[males_df['iso3'].isin(emro)]\n",
    "    females_df = females_df[females_df['iso3'].isin(emro)]\n",
    "\n",
    "    all_df = get_pivots(all_df)\n",
    "    males_df = get_pivots(males_df)\n",
    "    females_df = get_pivots(females_df)\n",
    "\n",
    "    # Save to files if needed\n",
    "    if save:\n",
    "        os.makedirs('scores/dash_cutoff/global', exist_ok=True)\n",
    "        all_df.to_csv('scores/dash_cutoff/nuts_legumes_all.csv')\n",
    "        males_df.to_csv('scores/dash_cutoff/nuts_legumes_males.csv')\n",
    "        females_df.to_csv('scores/dash_cutoff/nuts_legumes_females.csv')\n",
    "\n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "_,_,_ =get_dash_scores_nuts_legumes_combined(\n",
    "    nuts_file=r'..\\raw_data\\Country-level estimates\\v06_cnty.csv',\n",
    "    legumes_file=r'..\\raw_data\\Country-level estimates\\v05_cnty.csv',\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a function to sum the scores for countries \n",
    "def calc_total(path: str, suff: str):\n",
    "    all_glob = glob.glob(f'{path}/*_{suff}.csv')\n",
    "    cumulative_df = None\n",
    "    \n",
    "    for i in all_glob:\n",
    "        temp = pd.read_csv(i)\n",
    "        \n",
    "        if cumulative_df is None:\n",
    "            cumulative_df = temp\n",
    "        else:\n",
    "            cumulative_df.iloc[:, 1:] += temp.iloc[:, 1:]\n",
    "    \n",
    "    return cumulative_df\n",
    "\n",
    "folder = 'scores/dash_cutoff'  \n",
    "for i in ['all', 'males', 'females']:\n",
    "    temp_df = calc_total(folder, i)\n",
    "    temp_df.to_csv(f'{folder}/total_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in **dash_emro** we have scores based on how countries scored in the EMRO region\n",
    "\n",
    "and in **dash_global** we have thier scores based on how they scored across the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GLOBAL Scores***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['age','urban','edu']\n",
    "keep = [\n",
    "    'year','median','score'\n",
    "]\n",
    "def aio_v3_dash_glo(df: pd.DataFrame, food_group: str, scoring_scheme: str, pivot: bool=True):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame for DASH scoring:\n",
    "      1. Split the data (if applicable) into groups.\n",
    "      2. Apply the DASH scoring based on the provided food group and scoring scheme.\n",
    "      3. Restrict the DataFrame to the columns in the 'keep' list.\n",
    "      4. Optionally pivot the data.\n",
    "    \"\"\"\n",
    "    # Split the dataframe into three groups.\n",
    "    all_df, males_df, females_df = emro_select(df)\n",
    "    \n",
    "    # Apply dash scoring for each subgroup.\n",
    "    all_df = dash_score(all_df, food_group, scoring_scheme)\n",
    "    males_df = dash_score(males_df, food_group, scoring_scheme)\n",
    "    females_df = dash_score(females_df, food_group, scoring_scheme)\n",
    "    \n",
    "    # drop useless columns\n",
    "    all_df = all_df[keep]\n",
    "    males_df = males_df[keep]\n",
    "    females_df = females_df[keep]\n",
    "    \n",
    "    if pivot:\n",
    "        all_df = get_pivots(all_df)\n",
    "        males_df = get_pivots(males_df)\n",
    "        females_df = get_pivots(females_df)\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "def get_dash_scores_glo(name: str, save: bool, v0_codes: list, scoring_scheme: str):\n",
    "    \"\"\"\n",
    "    Sum the CSV files for a given food group, compute the DASH scores,\n",
    "    and optionally save the resulting DataFrames.\n",
    "    \"\"\"\n",
    "    def sum_csv_files(file_paths, sum_columns):\n",
    "        df_sum = None\n",
    "        non_sum_columns = None\n",
    "        for file in file_paths:\n",
    "            df = pd.read_csv(file)\n",
    "            # Separate the columns to sum and the rest.\n",
    "            df_sum_cols = df[sum_columns]\n",
    "            df_non_sum_cols = df.drop(columns=sum_columns)\n",
    "            if df_sum is None:\n",
    "                df_sum = df_sum_cols\n",
    "                non_sum_columns = df_non_sum_cols\n",
    "            else:\n",
    "                df_sum = df_sum.add(df_sum_cols, fill_value=0)\n",
    "        final_df = pd.concat([non_sum_columns, df_sum], axis=1)\n",
    "        return final_df\n",
    "\n",
    "    # Sum the CSV files (here summing the 'median' column).\n",
    "    total = sum_csv_files(v0_codes, sum_columns=['median'])\n",
    "    \n",
    "    # Compute DASH scores without pivoting.\n",
    "    all_df, males_df, females_df = aio_v3_dash_glo(total, food_group=name, scoring_scheme=scoring_scheme, pivot=False)\n",
    "    \n",
    "    # Create directory for saving the results.\n",
    "    os.makedirs('scores/dash_cutoff/global', exist_ok=True)\n",
    "    if save:\n",
    "        all_df.to_csv(f'scores/dash_cutoff/global/{name}_all.csv', index=False)\n",
    "        males_df.to_csv(f'scores/dash_cutoff/global/{name}_males.csv', index=False)\n",
    "        females_df.to_csv(f'scores/dash_cutoff/global/{name}_females.csv', index=False)\n",
    "    \n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "\n",
    "# List of tuples with (file paths, food group name, scoring scheme).\n",
    "luffy = [\n",
    "    ([r'..\\raw_data\\Global estimates\\v08_global.csv'], 'whole_grain', 'pos'),\n",
    "    ([r'..\\raw_data\\Global estimates\\v01_global.csv'], 'fruit', 'pos'),\n",
    "    ([r'..\\raw_data\\Global estimates\\v02_global.csv',\n",
    "      r'..\\raw_data\\Global estimates\\v04_global.csv'], 'veg', 'pos'),         ###?? I have included other starchy veggies as well \n",
    "    ([r'..\\raw_data\\Global estimates\\v15_global.csv'], 'SSB', 'neg'),          ###?? sugar?\n",
    "    # ([r'..\\raw_data\\Global estimates\\v35_global.csv'], 'sugar', 'neg'),\n",
    "    ([r'..\\raw_data\\Global estimates\\v57_global.csv',\n",
    "      r'..\\raw_data\\Global estimates\\v14_global.csv',\n",
    "      r'..\\raw_data\\Global estimates\\v13_global.csv'], 'dairy', 'pos'),\n",
    "    ([r'..\\raw_data\\Global estimates\\v09_global.csv',\n",
    "      r'..\\raw_data\\Global estimates\\v11_global.csv',                          ###!! ADDED Total seafoods\n",
    "      r'..\\raw_data\\Global estimates\\v10_global.csv'], 'meats', 'neg'),\n",
    "    ([r'..\\raw_data\\Global estimates\\v37_global.csv'], 'sodium', 'neg')\n",
    "]\n",
    "\n",
    "# Loop through each configuration and generate (and optionally save) the scores.\n",
    "for file_list, food_group, scheme in luffy:\n",
    "    get_dash_scores_glo(name=food_group, save=True, v0_codes=file_list, scoring_scheme=scheme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dash_scores_nuts_legumes_combined_global(nuts_file: str, legumes_file: str, save: bool = True):\n",
    "    \"\"\"\n",
    "    Combines nut and legume consumption (normalized), scores them according to DASH criteria,\n",
    "    and saves the resulting DataFrames in the same format as other DASH scoring outputs.\n",
    "    \"\"\"\n",
    "    # Load the datasets\n",
    "    df_nuts = pd.read_csv(nuts_file)\n",
    "    df_legumes = pd.read_csv(legumes_file)\n",
    "\n",
    "    # Normalize intakes\n",
    "    df_nuts['median'] = df_nuts['median'] / 28\n",
    "    df_legumes['median'] = df_legumes['median'] / 100\n",
    "\n",
    "    # Sum normalized values\n",
    "    df_combined = df_nuts.copy()\n",
    "    df_combined['median'] = df_nuts['median'] + df_legumes['median']\n",
    "\n",
    "    # Apply DASH scoring: score = 1 if median >= 5/7, else 0\n",
    "    df_combined['score'] = df_combined['median'].apply(lambda x: 1 if x >= 5/7 else 0)\n",
    "\n",
    "    # drop useless columns\n",
    "    all_df, males_df, females_df = emro_select(df_combined)\n",
    "    all_df = all_df[keep]\n",
    "    males_df = males_df[keep]\n",
    "    females_df = females_df[keep]\n",
    "    \n",
    "    # all_df = get_pivots(all_df)\n",
    "    # males_df = get_pivots(males_df)\n",
    "    # females_df = get_pivots(females_df)\n",
    "\n",
    "    # Save to files if needed\n",
    "    if save:\n",
    "        os.makedirs('scores/dash_cutoff/global', exist_ok=True)\n",
    "        all_df.to_csv('scores/dash_cutoff/global/nuts_legumes_all.csv')\n",
    "        males_df.to_csv('scores/dash_cutoff/global/nuts_legumes_males.csv')\n",
    "        females_df.to_csv('scores/dash_cutoff/global/nuts_legumes_females.csv')\n",
    "\n",
    "    return all_df, males_df, females_df\n",
    "\n",
    "_,_,_ =get_dash_scores_nuts_legumes_combined_global(\n",
    "    nuts_file=r'..\\raw_data\\Global estimates\\v06_global.csv',\n",
    "    legumes_file=r'..\\raw_data\\Global estimates\\v05_global.csv',\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a function to sum the scores for countries \n",
    "def calc_total_glo(path: str, suff: str):\n",
    "    all_glob = glob.glob(f'{path}/*_{suff}.csv')\n",
    "    cumulative_df = None\n",
    "    \n",
    "    for i in all_glob:\n",
    "        temp = pd.read_csv(i)\n",
    "        \n",
    "        if cumulative_df is None:\n",
    "            cumulative_df = temp\n",
    "        else:\n",
    "            cumulative_df.iloc[:, 1:] += temp.iloc[:, 1:]\n",
    "    cumulative_df.drop('median', axis=1,inplace=True)\n",
    "    return cumulative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'scores/dash_cutoff/global'  \n",
    "for i in ['all', 'males', 'females']:\n",
    "    temp_df = calc_total_glo(folder, i)\n",
    "    temp_df.to_csv(f'{folder}/total_{i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
